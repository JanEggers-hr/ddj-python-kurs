{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/ddj-python-kurs/blob/main/gude_welt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU48QhXoFEVm"
      },
      "source": [
        "# gude_welt.ipynb\n",
        "Ein erstes produktives Python-Skript.\n",
        "\n",
        "Für das Seminar \"Datenjournalismus\" im Sommersemester 2020\n",
        "Hochschule Darmstadt, Studiengang Onlinejournalismus, 6. Semester\n",
        "\n",
        "CC-BY Jan Eggers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAPy0qXrFEVn"
      },
      "source": [
        "## Was man über \"Notebooks\" wissen muss\n",
        "- Notebooks sind eine Mischung aus ausführbarem Code und Textblöcken.\n",
        "- Den Text gibt man als [\"Markdown\"](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) ein - mit einfachen Steuerbefehlen wie **\\*\\*fett\\*\\*** oder **\\# Überschrift**. \n",
        "- Wenn man einen Codeblock ausführt, gibt er das Ergebnis unter dem Block aus - wie es Python auf der Kommandozeile auch tun würde.\n",
        "- Man kann die Codeblöcke mit Shift+Enter ausführen und zum nächsten springen.\n",
        "\n",
        "Jetzt einfach mal ausprobieren: \n",
        "*Kursiv* und **fett** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDJJniVoFEVo"
      },
      "outputs": [],
      "source": [
        "1+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NMbtxDSFEVo"
      },
      "source": [
        "Und die traditionelle Begrüßung in einer neuen Programmiersprache: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj4VOlE0FEVp"
      },
      "outputs": [],
      "source": [
        "print(\"Gude Welt!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx2I21gkFEVp"
      },
      "source": [
        "## Vorbereitung: Bibliotheken laden\n",
        "Zusatzpakete statten Python mit Fähigkeiten zur Ein- und Ausgabe aus. Sie müssen in der jeweiligen Python-Umgebung installiert sein - wenn sie das nicht sind, muss man einmal auf die Kommandozeile und beispielsweise mit dem Befehl\n",
        "```conda install pandas```\n",
        "das Pandas-Paket installieren, das wir für Tabellen (\"Dataframes\") brauchen. \n",
        "\n",
        "(Wer Updates für ein Paket einspielen will, nutzt dazu den Befehl ```conda update ...``` oder einfach  ```conda update --all```)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLmtUCDnFEVp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWj0_AQkFEVq"
      },
      "source": [
        "Den obigen Textblock ausgeführt - und nichts ist passiert? Dann hat alles geklappt - und wir können loslegen. \n",
        "\n",
        "## Teil 1: CSV-Datei einlesen\n",
        "Wir lesen die CSV-Datei `plz-hessen.csv` in eine neue Variable namens plz_df und schauen sie uns danach kurz an.\n",
        "\n",
        "`plz-hessen.csv` ist ein gutartiges CSV: \n",
        "- Als Trennzeichen wird das Semikolon (\";\") verwendet, das keine Probleme mit Kommazahlen bereitet\n",
        "- Text ist in Anführungszeichen - und er enthält auch keine Steuerzeichen für Zeilensprünge, die gerne für Chaos sorgen\n",
        "- Der Zeichensatz der Datei ist UTF-8 - im Universal-Format gibt es keine Probleme mit Umlauten etc. \n",
        "\n",
        "Dass unser CSV nicht \"comma-separated\" ist, sondern \"Semikolon-separated\", müssen wir dem Befehl über den Zusatz `delimiter=\";\"` mitgeben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIfZbZJ9FEVq"
      },
      "outputs": [],
      "source": [
        "plz_df = pd.read_csv(\"plz-hessen.csv\",delimiter=\";\")\n",
        "plz_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2UqOaAUFEVr"
      },
      "source": [
        "Prima! Wir sehen, dass die Tabelle nur zwei Spalten enthält: Eine Spalte \"PLZ\" mit den Postleitzahlen, und eine Spalte \"Ort\" mit den Ortsnamen.\n",
        "\n",
        "Schauen wir uns mal die Dateitypen an. Dazu nutzen wir \"Eigenschaften\" und \"Methoden\" - Befehle, die wir direkt an den Variablennamen anhängen, durch einen Punkt getrennt, und die dem Computer sagen: Mach etwas mit dieser Variable. \n",
        "\n",
        "Was man mit einer Variable machen kann, hängt vom Dateityp ab - hier, bei unserer \"Dataframe\"- (Tabellen-) Variable `plz_df`, nutzen wir\n",
        "- eine Methode, die uns die Anzahl der Spalten zurückgibt - `plz_df.columns`\n",
        "- eine Methode, die den Dateityp einer Dataframe-Spalte zurückgibt - `plz_df.dtype`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x91PgrzTFEVr"
      },
      "outputs": [],
      "source": [
        "print(\"Der Dateityp von plz_df ist\",type(plz_df))\n",
        "\n",
        "print(\"Die Dateitypen der Spalten des Dataframes: \")\n",
        "for y in plz_df.columns:\n",
        "    print(y,plz_df[y].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXNDSSEFEVs"
      },
      "source": [
        "Dann können wir versuchen, die zweite Tabelle einzulesen, `ags-plz-lat-lon.csv`. \n",
        "Ich sag's gleich, das wird etwas schwieriger:\n",
        "- Sie nutzt Kommas.\n",
        "- Sie hat keine Anführungszeichen. \n",
        "- Sie nutzt einen anderen Zeichensatz. \n",
        "\n",
        "Aufgabe: Den nächsten Befehl ausprobieren - und so korrigieren, dass er funktioniert. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lRDdF-0bFEVs"
      },
      "outputs": [],
      "source": [
        "gemeinden_df = pd.read_csv(\"ags-plz-lat-lon.csv\",delimiter=\",\")\n",
        "gemeinden_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jAtIlNPFEVs"
      },
      "source": [
        "Okay, so geht's nicht - also den `delimiter` auf Komma ändern, das Komma auf  und in der [Pandas-Dokumentation für read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) nach dem richtigen Befehlszusatz suchen. (Das richtige Encoding für diese Datei ist übrigens der Windows-Zeichensatz `ISO-8859-1`.)\n",
        "\n",
        "Also versuchen wir's nochmal: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqye0c0KFEVs"
      },
      "outputs": [],
      "source": [
        "gemeinden_df = pd.read_csv(\"ags-plz-lat-lon.csv\",delimiter=\",\",encoding=\"ISO-8859-1\",decimal=\",\")\n",
        "gemeinden_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55cWjkTHFEVt"
      },
      "source": [
        "Jetzt werfen wir alle Zeilen, in denen Werte fehlen (was man an `NaN` sieht, \"Not a Number\") aus dem Dataframe. Wie wir das machen, [ergooglen wir uns einfach](https://lmgtfy.com/?q=python+drop+na+rows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaiDnuRXFEVt"
      },
      "outputs": [],
      "source": [
        "gemeinden_df = gemeinden_df.dropna()\n",
        "gemeinden_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drZknEE7FEVt"
      },
      "source": [
        "**Das hat funktioniert!**\n",
        "\n",
        "Allerdings wollen wir ja nur Hessen - also ziehen wir mal nur raus, was im Bundesland 6 (Hessen) spielt: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC8P3EdnFEVt"
      },
      "outputs": [],
      "source": [
        "gemeinden_df = gemeinden_df.query(\"Land == 6\")\n",
        "gemeinden_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqPOzqMFEVt"
      },
      "source": [
        "Auch das hat funktioniert.\n",
        "\n",
        "Allerdings: Wir haben noch keine AGS - wir müssen sie uns aus den Zahlenwerten für Land, Kreis und Gemeinde zusammensetzen, jeweils als String. (Es wäre einfacher gewesen, wir hätten die String-Wert in der Tabelle behalten!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdFX2abuFEVt"
      },
      "outputs": [],
      "source": [
        "ags_df = gemeinden_df.copy()\n",
        "for i in ags_df.index:\n",
        "    ags_df.loc[i,'AGS'] = \"0\"+str(int(ags_df.Land[i]*1000000+ags_df.RB[i]*100000+ags_df.Kreis[i]*1000+ags_df.Gem[i]))\n",
        "ags_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddNuP06QFEVu"
      },
      "source": [
        "*Eine kleine Anmerkung für alle, die schon programmiert haben und Python bisher nicht kennen: Vermutlich habt ihr euch über das ```.loc``` hinter dem Variablennamen gewundert - warum haben wir die Zelle im Dataframe nicht einfach über ```ags_df\\[spaltenname\\]\\[indexnr.\\] = wert``` verändert?*\n",
        "\n",
        "*Die Antwort hängt damit zusammen, dass Python die beiden Teile eines solchen Adressierungs-Befehls unabhängig voneinander ausführt - aus Sicht des Computers hieße das: Mach mal eine Kopie von einem Teil des Dataframes, und dann weise wieder da einem Teil davon etwas zu. So ist aber nicht sichergestellt, dass wir wirklich auf unsere Originaldaten schreiben - diese Verkettung von Befehlen finde ich wahnsinnig irritierend, ist aber halt so. Deshalb nutzen wir die Methode ```.loc```, die die Adressierung in einem Schritt erledigt. Was es mir ganz gut erklärt hat, war [dieser Artikel](https://www.dataquest.io/blog/settingwithcopywarning/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HtOyW_kFEVu"
      },
      "outputs": [],
      "source": [
        "# Das hier funktionert nicht bzw. produziert eine beeindruckende Warnung: \n",
        "for i in ags_df.index:\n",
        "    ags_df['AGS'] = \"0\"+str(int(ags_df.Land[i]*1000000+ags_df.RB[i]*100000+ags_df.Kreis[i]*1000+ags_df.Gem[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fnijNb4FEVu"
      },
      "source": [
        "Eins müssen wir noch reparieren: die Spalte `Bevoelkerung` enthält keine Zahl, sondern eine Zeichenkette, weil das Statistikamt gerne Leerzeichen als Trennzeichen benutzt. \n",
        "\n",
        "(Und wenn wir oben beim Import nicht noch `decimal=\",\"` angegeben hätten, um Python mitzuteilen, dass im Deutschen ein Komma als Dezimalpunkt dient, dann wären `Flaeche`, `Lat` und `Lon` auch noch Zeichenketten, weil sonst das Komma in den Koordinaten für Konfusion gesorgt hätte - seufz. \n",
        "\n",
        "Beweis gefällig? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6EomYFcFEVu"
      },
      "outputs": [],
      "source": [
        "print(\"Die Dateitypen der Spalten des Dataframes: \")\n",
        "ags_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YzOzLpOFEVv"
      },
      "source": [
        "Bevoelkerung ist ein ```object```, keine Zahl. Also müssen wir die Leerzeichen aus der Spalte `Bevoelkerung` werfen und dann alles in den richtigen Datentyp - int64 - umwandeln: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxVO9nwrFEVv"
      },
      "outputs": [],
      "source": [
        "for i in ags_df.index:\n",
        "    temp = ags_df.loc[i,'Bevoelkerung']    # String rausziehen\n",
        "    temp = str.replace(temp,\" \",\"\")        # Leerzeichen entfernen\n",
        "    ags_df.loc[i,'Bevoelkerung']=pd.to_numeric(temp)\n",
        "    \n",
        "ags_df\n",
        "#= ags_df.Bevoelkerung.str.replace(\" \",\"\")\n",
        "# ags_df.Bevoelkerung = pd.to_numeric(ags_df.Bevoelkerung)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnPA24BzFEVv"
      },
      "source": [
        "Hat geklappt!\n",
        "\n",
        "Jetzt noch ein bisschen aufräumen: die Postleitzahl in einen Integer-Wert umwandeln (eine ganze Zahl statt der ```float```-Kommazahl, die da steht), und die relevanten Spalten aussuchen. \n",
        "\n",
        "Dazu definieren wir zunächst eine Listen-Variable mit allen Spaltennamen, die wir haben wollen - und suchen dann aus, mit der Methode ```filter()```.\n",
        "\n",
        "(Der Zwischenschritt mit der Variable ```spalten``` ist nicht nur dazu da, um den Variablen-Typ \"Liste\" vorzustellen, sondern auch, weil ```filter()``` nicht mehr als fünf Parameter verarbeiten kann.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a4U2OB4FEVv"
      },
      "outputs": [],
      "source": [
        "ags_df['PLZ'] = ags_df['PLZ'].astype(int)\n",
        "spalten = ['AGS','Name','Flaeche','Bevoelkerung','PLZ','Lon','Lat','Besiedelung']\n",
        "ags_df = ags_df.filter(spalten)\n",
        "ags_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdNSGkQnFEVv"
      },
      "source": [
        "**Fertig!**  \n",
        "\n",
        "Jetzt führen wir die beiden Tabellen zusammen. \n",
        "\n",
        "## Teil 2: Tabellen zusammenführen\n",
        "\n",
        "Nehmen wir mal an, wir wollen eine Tabelle, in der man über die Postleitzahl die Stadt raussuchen kann - mit Bevölkerungszahl und Geokoordinaten. \n",
        "\n",
        "Wir erinnern uns, dass die Namen in der offiziellen Gemeindestatistik manchmal ein wenig wild sind. Wir brauchen also einen Ortsnamen, mit dem wir arbeiten können - den, der auch in der PLZ-Datei steht. Aber wie finden wir den passenden raus?\n",
        "\n",
        "Wer genau hingeschaut hat, hat gesehen: Auch die Tabelle `ags_df` enthält eine Postleitzahl (aber nur eine). Um wirklich für jede Postleitzahl eine Zeile in der Tabelle haben, müssen wir zwei Schritte gehen: \n",
        "\n",
        "- Erst mal den \"Ort\" aus der PLZ-Tabelle ```plz_df``` in die Tabelle mit aufnehmen. \n",
        "- Dann Zeilen für alle PLZ-Werte für den entsprechenden Ort anlegen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvTJ4HWNFEVv"
      },
      "outputs": [],
      "source": [
        "ags_mit_ort_df = pd.merge(left=ags_df, right=plz_df, left_on='PLZ', right_on='PLZ', how='left')\n",
        "ags_mit_ort_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEVAop3sFEVv"
      },
      "source": [
        "Die Spalte \"Ort\" können wir jetzt verwenden, um nochmal einen ```merge()``` mit der Postleitzahl-Tabelle zu machen - nur diesmal als \"right merge\", wo alle Werte aus der \"rechten\" Tabelle (also der PLZ-Tabelle) verwendet werden sollen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF_XSu0ZFEVv"
      },
      "outputs": [],
      "source": [
        "ags_mit_ort_df[ags_mit_ort_df.Name.str.find(\"Bad\") != -1]\n",
        "#ags_mit_ort_df[ags_mit_ort_df.AGS==\"06434001\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKv5WeYnFEVv"
      },
      "outputs": [],
      "source": [
        "zusammen_df = pd.merge(left=ags_mit_ort_df, right=plz_df, left_on='Ort', right_on='Ort', how='right')\n",
        "zusammen_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa2V_pnaFEVv"
      },
      "source": [
        "## Teil 3: Tabelle als Excel-Datei ausgeben\n",
        "Und jetzt hätten wir das Ganze gerne wieder als Excel-Datei. Das ist zum Glück einfach.\n",
        "\n",
        "Die Parameter sagen: Spaltennamen mit in die Tabelle schreiben, Zeilennummern (den Index) nicht - bei anderen Pandas-Tabellen kann der Index wichtige Daten enthalten, deshalb ist das wichtig. Und Zahlen mit Komma ausgeben! Alle Formatierungsbefehle für `to_excel` finden sich [in der Pandas-Dokumentation.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtZ_9hslFEVv"
      },
      "outputs": [],
      "source": [
        "zusammen_df.to_excel ('export.xlsx', index = False, header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dROz3ZfMFEVv"
      },
      "source": [
        "## Teil 4: Zusatzaufgabe\n",
        "\n",
        "Bis hierher gekommen? Herzlichen Glückwunsch! Dann mal diesen Code hier ausführen: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aK6kBDnFEVv"
      },
      "outputs": [],
      "source": [
        "cyphertext = b'R3V0ZW4gTW9yZ2VuISBJY2ggaG9mZmUsIGFsbGUgc2luZCBnZXN0ZXJuIGVpbmlnZXJtYcOfZW4ga2xhciBnZWtvbW1lbiAtIHVuZCBpaHIga29ubnRldCBldWNoIGdlZ2Vuc2VpdGlnIGhlbGZlbi4gRGFua2UgZsO8ciBkaWUgQmVyZWl0c2NoYWZ0LCBzaWNoIGRhcmF1ZiBlaW56dWxhc3NlbiEgLS0gRGllIEJlcmVjaHRpZ3VuZ2VuIGbDvHIgTGltZVN1cnZleSBoYWJlIGljaCBoZXV0ZSBtb3JnZW4gbm9jaCBtYWwgYW5nZXBhc3N0OyBqZXR6dCBtw7xzc3RlIGVzIHp1bWluZGVzdCBiZWkgZGVuIG1laXN0ZW4gZnVua3Rpb25pZXJlbi4gQml0dGUgbWVsZGVuLCB3ZW5uIG5pY2h0LiBVbmQgZW50c2NodWxkaWd0LCBkYXNzIGljaCBkYXMgZ2VzdGVybiBuaWNodCBtZWhyIGdlc2NoYWZmdCBoYWJlOyBkYW5rZSBmw7xyIGV1cmUgR2VkdWxkLg=='\n",
        "\n",
        "import base64\n",
        "print(base64.standard_b64decode(cyphertext).decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPG_eOg5FEVw"
      },
      "source": [
        "**Nur Mut! Man kann nichts kaputt machen!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}